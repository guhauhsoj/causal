---
title: "Propensity Score"
output: html_document
---
```{r}
library(ggplot2)
#USDA Data on food accessability by census tract
USDA <- read.csv("./data/USDA.csv")
#CDC Data on average life expectancy by census tract
life_exp <- read.csv("./data/US_A.csv")

#removes some track data do to missing observations in life expectancy data, 74,000 rows to 65000 rows
USDA_Data <- dplyr::inner_join(life_exp, USDA, by = c("Tract.ID"="CensusTract") )

```

## Preprocessing and covariate selection

Include important covariates: Median Household income, % of households who recieve SNAP, % who have access to a vehicle. Assume strong ignorability given these covariates

```{r}
#list covariates, response and treatment
race <- c("TractBlackper","TractHispanicper")
myvars <- c("e.0.","LA1and10","PovertyRate","MedianFamilyIncome", "TractSNAPper","Urban","TractHUNVper",race)


#normalize SNAP as a % of hoursing units in the tract, % of houses with no vehicle in the tract and % of each race in tract
USDA_Data$TractSNAPper = USDA_Data$TractSNAP / USDA_Data$OHU2010
USDA_Data$TractHUNVper = USDA_Data$TractHUNV / USDA_Data$OHU2010

USDA_Data$TractBlackper = USDA_Data$TractBlack/USDA_Data$POP2010
USDA_Data$TractWhiteper = USDA_Data$TractWhite/USDA_Data$POP2010
USDA_Data$TractHispanicper = USDA_Data$TractHispanic/USDA_Data$POP2010



#create new data and filter NA,NAN and Inf
USDA_new <- USDA_Data[myvars]
#make sure if its not systematically missing data
USDA_new <- USDA_new[Reduce(`&`, lapply(USDA_new, function(x) !is.na(x)  & is.finite(x))),]
USDA_new <- USDA_new[USDA_new$MedianFamilyIncome !=0,]
USDA_new <- USDA_new[USDA_new$TractSNAPper <= 1 & USDA_new$TractHUNVper <= 1,]



```


## Propensity Score

Naive propensity score:

```{r}
#income standardized or not, it doesnt effect the scores
covars <- c("PovertyRate","MedianFamilyIncome","TractSNAPper","TractHUNVper","Urban",race)

x <- as.matrix(USDA_new[covars])
x <- scale(x)
y <- USDA_new$LA1and10
prop.logit <- glm(y ~ x, family = "binomial")

prop <- predict(prop.logit,USDA_new[covars],type = "response")

USDA_new$prop_scores <- prop

hist(prop)

#looking at truncated scores

prop_trunc <- pmax(.1,pmin(.9,prop))

hist(prop_trunc)
```

IPW Horvitz-Thompson estimator and IPW Hajek estimator and bootstrap inference

```{r}

ipw.est = function(z, y, x, truncpscore = c(0, 1))
{
  ## fitted propensity score
  pscore   = glm(z ~ x, family = binomial)$fitted.values
  pscore   = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
  
  ace.ipw0 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
  ace.ipw  = mean(z*y/pscore)/mean(z/pscore) - 
    mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))

  return(c(ace.ipw0, ace.ipw))     
}


ipw.boot = function(z, y, x, n.boot = 500, truncpscore = c(0, 1))
{
  point.est  = ipw.est(z, y, x, truncpscore)
  
  ## nonparametric bootstrap
  n.sample   = length(z)
  x          = as.matrix(x)
  boot.est   = replicate(n.boot, 
                         {id.boot = sample(1:n.sample, n.sample, replace = TRUE)
                         ipw.est(z[id.boot], y[id.boot], x[id.boot, ], truncpscore)})
  boot.se    = apply(boot.est, 1, sd)
  
  res = rbind(point.est, boot.se)
  rownames(res) = c("est", "se")
  colnames(res) = c("HT", "Hajek")
  
  return(res)
}

```


ATE point estimate on our data:

```{r}


x <- USDA_new[covars]
z <- USDA_new$LA1and10
y <- USDA_new$e.0.

x <- scale(x)

IPW.est <- ipw.est(z,y,x)
IPW_HT <- IPW.est[1]
IPW_Hajek <- IPW.est[2]

#point estimates
cbind(IPW_HT,IPW_Hajek)

```

Inference and covariate balance check (not good covariate balance):

```{r}
#confidence intervals
results <- ipw.boot(z,y,x)
rbind(c(results[1,1]-1.96*results[2,1], results[1,1]+1.96*results[2,1]),c(results[1,2]-1.96*results[2,2], results[1,2]+1.96*results[2,2]))

## balance check based on Hajek
Bcheck = sapply(1:dim(x)[2],
                FUN = function(px){
                  ipw.boot(z, x[, px], x)[, 2]
                })


dat_balance = data.frame(est = Bcheck[1, ],
                         upper = Bcheck[1, ] + 1.96*Bcheck[2, ],
                         lower = Bcheck[1, ] - 1.96*Bcheck[2, ],
                         cov = factor(1:ncol(x)))
ggplot(dat_balance) + 
  geom_errorbar(aes(x = cov,
                    ymin = lower,
                    ymax = upper),
                alpha = 0.6) + 
  geom_point(aes(x = cov,
                 y = est),
             alpha = 0.6) +
  geom_hline(aes(yintercept = 0),
             alpha = 0.3) + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.title.y=element_blank()) +
  xlab("balance check based on weighting")
ggsave("balance_PShajek.pdf", height = 3, width = 8)
```



Using various truncation scores:

```{r}

trunc.list = list(trunc0 = c(0,1), 
                  trunc.01 = c(0.01, 0.99), 
                  trunc.05 = c(0.05, 0.95), 
                  trunc.1 = c(0.1, 0.9))
trunc.est = lapply(trunc.list,
                   function(t){
                     est = ipw.boot(z, y, x, truncpscore = t)
                     round(est, 3)
                   })
trunc.est

#balance check with truncated
Bcheck = sapply(1:dim(x)[2],
                FUN = function(px){
                  ipw.boot(z, x[, px], x,truncpscore=c(0.1, 0.9))[, 2]
                })

dat_balance = data.frame(est = Bcheck[1, ],
                         upper = Bcheck[1, ] + 1.96*Bcheck[2, ],
                         lower = Bcheck[1, ] - 1.96*Bcheck[2, ],
                         cov = factor(1:ncol(x)))
ggplot(dat_balance) + 
  geom_errorbar(aes(x = cov,
                    ymin = lower,
                    ymax = upper),
                alpha = 0.6) + 
  geom_point(aes(x = cov,
                 y = est),
             alpha = 0.6) +
  geom_hline(aes(yintercept = 0),
             alpha = 0.3) + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.title.y=element_blank()) +
  xlab("balance check based on weighting")

```
